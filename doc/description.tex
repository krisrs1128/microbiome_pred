\documentclass{article}
\usepackage[autostyle]{csquotes}  
\include{preamble}

\title{Abundance Modeling for Exploratory Micribiome Analysis}
\author{Kris Sankaran}

\begin{document}
\maketitle

\begin{displayquote}
The success of a theory is best judged from its ability to predict
  in new contexts.
\end{displayquote}

This comment appeared in D.R. Cox's discussion of \cite{breiman2001statistical},
and it will serve as the point of departure in our effort to better understand
the microbiome using machine learning models. The idea is that microbiome
researchers are trying to get their hands on a theory\footnote{While I'm quoting
  things, here's another relevant one: ``There is nothing so practical as a good
  theory'' -- Kurt Lewin} of the bacterial ecology and the associated medical
consequences. For example, can the theory predict what happens to the abundance
of Bacteroides in the short and long run, when a patient undergoes a colon
cleanout?

Building prediction models for bacterial abundances has never been that
intrinsically interesting (in the same way it is in finance or online search,
say, though maybe things will change if personalized microbiome abundance
becomes common practice). We argue however that, while the $\hat{y}_{i}$'s
generated by such a model might not be particularly significant in and of
themselves, there are two ways these $\hat{y}_{i}$'s can be used to guide real
theory-building,

\begin{itemize}
\item Data Reduction: An algorithm's prediction surface thought of as a kind of
  smoothing of the raw data. One of the key goals of statistics is to help
  compress the variation in a complex system into a few easily understandable
  components, and there is no reason why these response surfaces need to be
  thought of differently than the curves / surfaces learned by, say, smoothing
  splines or PCA, for example, except perhaps they may be somewhat more
  complicated to understand directly.
\item Characterizing Uncertainty: The test error in a machine learning algorithm
  gives a sense of how powerful the theory is / how much intrinsic noise there
  is the system under study.
\end{itemize}

\section{Methods}

\subsection{Features}

\subsection{Interpretation}

\subsection{Infrastructure}

\section{Case Studies}

\subsection{Cleanout Perturbation Study}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.4]{figure/phylo_ix_motivation.pdf}
  \caption{Abundances across the tree. Note the ``zero plus positive part'' structure, after arcsinh transforming. \label{fig:label} }
\end{figure}


\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.4]{figure/xgboost_prop_preds.pdf}
  \caption{Fitted probability of being zero vs. nonzero. Note that for oders with fewer counts (wide bars), the model predictions default to (essentially) the global mean.\label{fig:label} }
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{figure/phylo_ix_preds.pdf}
  \caption{I had actually input the feature incorrectly in these models -- the colors are actually supposed to be clustered near one another. The doc will be updated once I rerun the models. \label{fig:label} }
\end{figure}

\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}
